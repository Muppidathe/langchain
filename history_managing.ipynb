{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e115e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages([('system','you are a helpfull ai assistant'),'{messages}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "45edeafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "model=Ollama(model='qwen3:4b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d72b58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store={}\n",
    "def get_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableParallel\n",
    "from operator import itemgetter\n",
    "trimmer=trim_messages(max_tokens=500,strategy='last',allow_partial=False,include_system=True,token_counter=model)\n",
    "# def chains(inp):\n",
    "#     output=trimmer.invoke(inp['messages'])\n",
    "#     output=prompt.invoke(output)\n",
    "#     output=model.invoke(output)\n",
    "#     return output\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "# chain = RunnableLambda(chains)\n",
    "chain=RunnablePassthrough().assign(messages=itemgetter('messages')|trimmer)|prompt|RunnableParallel() |model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c7480c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user sent a message saying \"hi my name is arun\". Let me think about how to respond. Since the system says I should be helpful, I need to greet them back and maybe ask how I can assist. I should keep it friendly and open-ended. Maybe say \"Hello Arun! How can I assist you today?\" That sounds good. Let me make sure there\\'s no need for any special formatting here. The user didn\\'t ask a question, so just a polite response. Alright, that\\'s it.\\n</think>\\n\\nHello Arun! How can I assist you today?'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory,RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage\n",
    "app=RunnableWithMessageHistory(chain,get_history,input_messages_key='messages')\n",
    "configu={'configurable':{'session_id':'chat1'}}\n",
    "app.invoke({'messages':HumanMessage(content='hi my name is arun')} , config=configu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647b559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='you are a helpfull ai assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='[HumanMessage(content=\\'what is 2+2\\', additional_kwargs={}, response_metadata={}), AIMessage(content=\\'<think>\\\\nOkay, the user asked, \"what is 2+2\". Let me think. Well, 2 plus 2 is a basic arithmetic problem. The answer should be 4. But wait, maybe they want more details? Like, maybe they\\\\\\'re a kid learning addition and need an explanation. Or perhaps they\\\\\\'re testing if I know the basic math. I should confirm the answer and maybe add a simple explanation. Let me make sure there\\\\\\'s no trick here. The question seems straightforward. So the response is 4. I\\\\\\'ll just state that clearly.\\\\n</think>\\\\n\\\\nThe result of 2 + 2 is 4.\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'hi my name is arun\\', additional_kwargs={}, response_metadata={}), AIMessage(content=\\'<think>\\\\nOkay, the user sent another \"hi my name is arun\" message. Let me check the history. Previously, they introduced themselves, and I responded with a greeting. Then they asked 2+2, which I answered. Now they\\\\\\'re saying hi again. Maybe they\\\\\\'re testing if I remember their name or just starting a conversation. Since they mentioned their name again, I should acknowledge it again. But maybe they just want to continue the conversation. I should keep it friendly and open. Let me respond with a greeting and ask how I can help again. No need for markdown, just plain text. Make sure it\\\\\\'s polite and helpful.\\\\n</think>\\\\n\\\\nHello, Arun! How can I assist you today?\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'what is 2+2\\', additional_kwargs={}, response_metadata={}), AIMessage(content=\\'<think>\\\\nOkay, the user is asking \"what is 2+2\" again. Let me check the history. They first asked that, and I answered 4. Then they introduced themselves as Arun, and I greeted them. Now they\\\\\\'re asking the same math problem again. Maybe they\\\\\\'re testing if I know the answer, or they might have a follow-up question. Since it\\\\\\'s the same question, I should confirm the answer again. But maybe they need more details? Or perhaps they\\\\\\'re confused and want an explanation. I should keep it simple and direct. The answer is definitely 4. I\\\\\\'ll state that clearly again.\\\\n</think>\\\\n\\\\nThe result of 2 + 2 is 4.\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'what is 2+2\\', additional_kwargs={}, response_metadata={})]', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user is asking \"what is 2+2\" for the third time. Let me check the conversation history. The first time, I answered 4. Then they introduced themselves as Arun, and I greeted them. The second time they asked 2+2 again, I gave the same answer. Now they\\'re asking once more. It\\'s possible they\\'re just testing if I know the answer, or maybe they need a different explanation. But since the question is straightforward, the answer is definitely 4. I should respond clearly again. Maybe they need confirmation, so I\\'ll state the answer and maybe add a friendly note to see if they need anything else.\\n</think>\\n\\nThe result of 2 + 2 is 4. Let me know if you need help with anything else!'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({'messages':HumanMessage(content='what is 2+2')},config=configu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5681da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError('Expected str, BaseMessage, list[BaseMessage], or tuple[BaseMessage]. Got messages=[SystemMessage(content=\\'you are a helpfull ai assistant\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"[HumanMessage(content=\\'who are you\\', additional_kwargs={}, response_metadata={})]\", additional_kwargs={}, response_metadata={})].')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='you are a helpfull ai assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"[HumanMessage(content='who are you', additional_kwargs={}, response_metadata={})]\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({'messages':'who are you'},config=configu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6ac004e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user just asked, \"what is my name\". Let me see. The previous message was from the user saying \"hi my name is arun\", and I responded with a greeting. Now they\\'re asking \"what is my name\". Wait, that\\'s a bit confusing. If the user is asking for their own name, they might be testing if I remember it. In the history, they mentioned their name is Arun. So I should confirm that. But maybe they\\'re confused or want to verify. I need to respond clearly. Let me check the system message again. The system says I should be helpful. So I should tell them their name is Arun, as they mentioned earlier. But maybe they want to make sure I remember correctly. I should state it directly. Also, maybe ask how I can help them further. Let me make sure the response is friendly and confirms their name. So the answer would be \"Your name is Arun. How can I assist you today?\" That seems right. No need for any other steps here. Just a straightforward reply.\\n</think>\\n\\nYour name is Arun. How can I assist you today?'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({'messages':HumanMessage(content='what is my name')},config=configu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b7caa2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='hi my name is arun', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\nOkay, the user sent a message saying \"hi my name is arun\". Let me think about how to respond. Since the system says I should be helpful, I need to greet them back and maybe ask how I can assist. I should keep it friendly and open-ended. Maybe say \"Hello Arun! How can I assist you today?\" That sounds good. Let me make sure there\\'s no need for any special formatting here. The user didn\\'t ask a question, so just a polite response. Alright, that\\'s it.\\n</think>\\n\\nHello Arun! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='<think>\\nOkay, the user just asked, \"what is my name\". Let me see. The previous message was from the user saying \"hi my name is arun\", and I responded with a greeting. Now they\\'re asking \"what is my name\". Wait, that\\'s a bit confusing. If the user is asking for their own name, they might be testing if I remember it. In the history, they mentioned their name is Arun. So I should confirm that. But maybe they\\'re confused or want to verify. I need to respond clearly. Let me check the system message again. The system says I should be helpful. So I should tell them their name is Arun, as they mentioned earlier. But maybe they want to make sure I remember correctly. I should state it directly. Also, maybe ask how I can help them further. Let me make sure the response is friendly and confirms their name. So the answer would be \"Your name is Arun. How can I assist you today?\" That seems right. No need for any other steps here. Just a straightforward reply.\\n</think>\\n\\nYour name is Arun. How can I assist you today?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store['chat1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6cfb0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hi! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is the weathr?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Your actual chain (must expect a dict with \"messages\" key)\n",
    "chain = RunnablePassthrough()  # example placeholder\n",
    "\n",
    "# Your session history fetcher\n",
    "def get_history(session_id: str):\n",
    "    history = ChatMessageHistory()  # ✅ creates object with .messages property\n",
    "    history.add_user_message(\"Hello\")\n",
    "    history.add_ai_message(\"Hi! How can I help you today?\")\n",
    "    return history\n",
    "\n",
    "# Wrap with history\n",
    "app = RunnableWithMessageHistory(chain, get_history,input_messages_key='messages')\n",
    "\n",
    "# Call with new input and config (note the session_id)\n",
    "config = {\"configurable\": {\"session_id\": \"user123\"}}\n",
    "app.invoke({\"messages\": \"What is the weathr?\"}, config=config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
