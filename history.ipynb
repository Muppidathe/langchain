{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages([('system','you are a helpfull assitant'),('user','{messages}')])\n",
    "model=Ollama(model='qwen3:4b')\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f8c4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "msg={}\n",
    "def get_hist(session_id)->BaseChatMessageHistory:\n",
    "    if session_id not in msg:\n",
    "        msg[session_id]=ChatMessageHistory()\n",
    "    return msg[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21b8e927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user introduced themselves as Muppidathi. I need to respond politely and offer assistance. Let me start by acknowledging their name and asking how I can help. Keep it friendly and open-ended. Make sure the response is concise and inviting. Alright, that should do it.\\n</think>\\n\\nHello, Muppidathi! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "app=RunnableWithMessageHistory(chain,get_hist)\n",
    "chat={'configurable':{'session_id':'chat1'}}\n",
    "response=app.invoke({'messages':'my name is muppidathi'},config=chat)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17a7e59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user just asked, \"what is my name\". Let me think. Previously, they introduced themselves as Muppidathi. So, the assistant should confirm that name.\\n\\nBut wait, maybe the user is testing if the assistant remembers previous interactions. The assistant\\'s last response was a greeting, and the user is now asking for their name. The assistant needs to respond accurately based on the history.\\n\\nIn the system message, the user\\'s name was given as Muppidathi. So the correct answer is to state that. But the user might be confused or checking if the assistant is paying attention. The response should be straightforward, confirming the name from the previous message.\\n\\nI should make sure the response is clear and direct. No need for extra information since the user is simply asking for their own name. The assistant should provide the correct answer based on the provided history.\\n</think>\\n\\nHello, your name is Muppidathi. Let me know how I can assist you further! ðŸ˜Š'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat={'configurable':{'session_id':'chat1'}}\n",
    "response=app.invoke({'messages':'what is my name'},config=chat)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
